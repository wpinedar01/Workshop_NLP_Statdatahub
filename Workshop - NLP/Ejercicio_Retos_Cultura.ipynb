{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c691cc9a-2e1a-4206-92ec-953532456c44",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/statdatahub.png\" width=\"200\"/>\n",
    "</div>\n",
    "\n",
    "# Explorando el Lenguaje: Introducción a la Minería de Textos y NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1bd228-8f25-423a-ab67-a09c24fc92a0",
   "metadata": {},
   "source": [
    "<h2>Introducción</h2>\n",
    "<p><strong>Contexto del problema</strong>. En la actualidad, los relatos y narrativas sobre los desafíos culturales que enfrenta Colombia son una fuente invaluable de información para analizar los retos que enfrenta el país en esta área. Estos textos, que van desde opiniones de expertos hasta comentarios ciudadanos, reflejan una diversidad de perspectivas y matices que pueden ser analizados mediante técnicas de procesamiento de lenguaje natural (NLP). Este ejercicio busca aplicar herramientas como Bag of Words (BOW), One-Hot Encoding y el cálculo de la frecuencia inversa de documentos (TfIDF) para extraer información clave, identificar patrones comunes y entender las principales preocupaciones y retos relacionados con la cultura en Colombia. El análisis de texto nos permitirá clasificar, interpretar y agrupar estos relatos para obtener una visión más clara sobre los retos culturales más urgentes.</p>\n",
    "\n",
    "<p><strong>Contexto analítico</strong>. El archivo de datos \"retos_culturales_colombia.csv\" contiene textos narrativos que describen los desafíos culturales de Colombia. Cada fila corresponde a un relato, y las columnas contienen diversas características del texto. Para el análisis, se aplicarán técnicas como Bag of Words, que convierte los relatos en matrices de frecuencia de palabras; One-Hot Encoding, que representa las palabras como vectores binarios; y TfIDF, que pondera la importancia de cada palabra en función de su frecuencia en el corpus. Estas técnicas permitirán detectar las palabras más relevantes y establecer relaciones entre los diferentes relatos, facilitando así la identificación de temas recurrentes y patrones ocultos en los datos textuales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a58568-21fe-4eb1-8478-7017a011e909",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3a76b-83ce-4bad-8202-2574a7b86e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk # imports the natural language toolkit\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d973a1-f4ae-4812-9eae-72888fc4961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar Conjunto de datos\n",
    "data = pd.read_excel('data/retos_culturales_colombia.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d81e33-b4ea-4909-9523-8811d778cacd",
   "metadata": {},
   "source": [
    "# Preprocesamiento de textos\n",
    "\n",
    "- **Para qué?:** Para eliminar signos de puntuación y palabras conectoras (stopwords) que no nos aportan al análisis del texto.\n",
    "- **Por qué?:** Obtenemos un vocabulario más limpio, lo que nos permitirá generar resultados más confiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287db2e0-5b5a-488f-9525-e89c70451e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllReviews = data['Reto']\n",
    "AllReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669147d5-8c46-4e38-8839-806bab1f2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(AllReviews)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70637d06-9983-4759-a751-faf7ea2df7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllReviews=[AllReviews[index].lower() for index in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e398c8-0e01-4c7e-9bf4-3cf70952bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar puntuaciones\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "AllReviews2 = AllReviews.copy()\n",
    "\n",
    "for op in range(n):\n",
    "    my_str = AllReviews[op]\n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "       if char not in punctuations:\n",
    "           no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    AllReviews2[op]=no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a343af-9898-41f4-9ead-dc3aae52ee87",
   "metadata": {},
   "source": [
    "# Eliminación de stopwords\n",
    "\n",
    "- **Para qué:** Eliminar palabras comunes que probablemente aparecerán en cualquier texto\n",
    "- **Por qué:** Ellas no te dicen mucho sobre tu texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45271c-ab2f-4c9e-b9b7-41af64df4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"spanish\"))\n",
    "AllReviews3 = AllReviews2.copy()\n",
    "\n",
    "for op in range(n):\n",
    "    without_stop_words = []\n",
    "    stopword = []\n",
    "    sentence = AllReviews2[op]\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            stopword.append(word)\n",
    "        else:\n",
    "            without_stop_words.append(word)\n",
    "    AllReviews3[op]= ' '.join(without_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3eb29f-5d3c-451a-8a9a-4cd3f5646dec",
   "metadata": {},
   "source": [
    "# Derivación y lematización\n",
    "\n",
    "**Derivación:**\n",
    "\n",
    "- **Para qué:** Reducir una palabra a su forma base/raíz\n",
    "- **Por qué:** A menudo tiene sentido tratar las palabras relacionadas de la misma manera.\n",
    "- **Comentarios:**\n",
    "    - Utiliza un enfoque basado en reglas \"simple\" y rápido\n",
    "    - Las palabras derivadas generalmente no se muestran a los usuarios (se utilizan para análisis/indexación)\n",
    "    - Algunos motores de búsqueda tratan las palabras con la misma raíz como sinónimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8638d53-20a4-4fb5-8d04-fb76c4ceea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize stemmer\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677f726-7b43-4fff-b01c-601b58181415",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(AllReviews3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8ba2d-6383-4c3a-beb9-1cc294787dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(vect.vocabulary_.keys())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f2b99-8d00-4501-ba40-fda840c62337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem each word\n",
    "print([stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d31a26-57a1-4c34-b7f3-f92f526144de",
   "metadata": {},
   "source": [
    "**Lematización**\n",
    "\n",
    "- **Para qué:** Derivar la forma canónica ('lema') de una palabra\n",
    "- **Por qué:** Puede ser mejor que el uso de la derivación\n",
    "- **Comentario:** Utiliza un enfoque basado en diccionario (más lento que la derivación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad45533-7749-4c14-a0a6-2b9b2954ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55222efc-fad7-4a0d-b6d9-bcfd7c60b838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assume every word is a noun\n",
    "print([wordnet_lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4f932-170f-4583-bdca-c7518ea3a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume every word is a verb\n",
    "print([wordnet_lemmatizer.lemmatize(word,pos='v') for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cce34a-72ab-443e-af03-4c064e9efa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns a list of lemmas\n",
    "def split_into_lemmas(text):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return [wordnet_lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80338fbb-6189-42b1-aa97-67781975578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0270e6-4312-44be-82a5-bef9b607b928",
   "metadata": {},
   "source": [
    "# Tokenización\n",
    "\n",
    "- **Para qué?:** Separar el texto en unidades como oraciones o palabras.\n",
    "- **Por qué?:** Da estructura a un texto previamente no estructurado\n",
    "- **Comentario:** Relativamente fácil con textos en inglés, no fácil con algunos idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f3aef-14f0-4c54-afc9-2a847faf3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X\n",
    "X_dtm = vect.fit_transform(AllReviews3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adcf83-b9b9-4971-b2a8-de15d35a91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de372059-3105-456a-bc88-d7af77d7331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70970f6-ff91-4676-a2c1-d153a1028034",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=X_dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfaf539-03ea-416b-911c-a32a701b6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "out = dict(itertools.islice(vect.vocabulary_.items(), 5)) \n",
    "\n",
    "str(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016bd28-3f45-4a60-97f2-e2d45251956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows are documents, columns are terms (aka \"tokens\" or \"features\")\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057c4a8-d9b7-4c42-9004-b61dd96fae5b",
   "metadata": {},
   "source": [
    "# n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19f080-01dc-448d-840f-a42b0fa4e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "def top_k_ngrams(word_tokens,n,k):\n",
    "    \n",
    "    ## Getting them as n-grams\n",
    "    n_gram_list = list(ngrams(word_tokens, n))\n",
    "\n",
    "    ### Getting each n-gram as a separate string\n",
    "    n_gram_strings = [' '.join(each) for each in n_gram_list]\n",
    "    \n",
    "    n_gram_counter = Counter(n_gram_strings)\n",
    "    most_common_k = n_gram_counter.most_common(k)\n",
    "    return(most_common_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0615830-d114-41bd-a2ca-632cbb72d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_reviews_text = ' '.join(AllReviews3)\n",
    "tokenized_words = nltk.word_tokenize(all_reviews_text)\n",
    "\n",
    "tri_gramas=top_k_ngrams(tokenized_words, 3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00a4b0-6a9c-497b-99b6-623c7b3396b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29d2cc-4b1a-4bd4-8d01-c9034ed64a79",
   "metadata": {},
   "source": [
    "#  Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "- **Para qué:** Calcula la \"frecuencia relativa\" con la que aparece una palabra en un documento en comparación con su frecuencia en todos los documentos.\n",
    "- **Por qué:** Más útil que \"frecuencia de términos\" para identificar palabras \"importantes\" en cada documento (alta frecuencia en ese documento, baja frecuencia en otros documentos)\n",
    "- **Comentario:** Se utiliza para puntuación de motores de búsqueda, resumen de texto y agrupamiento de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8927de-b5d2-44a1-8ed0-7595ac303a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a document-term matrix using TF-IDF\n",
    "vect = TfidfVectorizer()\n",
    "dtm = vect.fit_transform(AllReviews3)\n",
    "X = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "features = vect.vocabulary_.keys()\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89602598-bda4-4830-924b-11afdca92a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random text\n",
    "review_id = 40\n",
    "review_text = AllReviews3[review_id]\n",
    "review_length = len(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf79c4-4126-4d4f-9e7c-9516b4d4a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of words and their TF-IDF scores\n",
    "word_scores = {}\n",
    "for word in vect.vocabulary_.keys():\n",
    "    word = word.lower()\n",
    "    if word in features:\n",
    "        word_scores[word] = dtm[review_id, list(features).index(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332c19d-0fd0-4316-8509-ed11562595b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print words with the top 5 TF-IDF scores\n",
    "print('TOP SCORING WORDS:')\n",
    "top_scores = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for word, score in top_scores:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe7745-3c93-46a1-94f1-6277c4ca858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Se eligen 5 grupos por el método \n",
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=500, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1153e-b8f8-445d-a544-f14ec35fcdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6f052-4a87-4f0c-9dbc-fd998ceb85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34b492-bfcf-4d6b-ac51-1b51ac0883a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install threadpoolctl==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2890e0b-9d20-4719-b178-9d5281cb57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction\")\n",
    "predicted = model.predict(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864db78-3302-438f-bf40-0c47682cb125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cluster'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a8dcf-cda3-466c-b9c9-2047448140bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.query(\"Cluster==0\").iloc[:10]['Reto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ecb6b-985d-4528-b50a-609b81270a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.query(\"Cluster==1\").iloc[:10]['Reto'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
