{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa61091-f450-4dcb-84a1-04870e6e4f83",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/statdatahub.png\" width=\"200\"/>\n",
    "</div>\n",
    "\n",
    "# Explorando el Lenguaje: Introducción a la Minería de Textos y NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac3933-a208-4cda-acc0-cf6c8efc3684",
   "metadata": {},
   "source": [
    "Este Workshop sobre Procesamiento del Lenguaje Natural explicará cómo construir sistemas que aprenden y se adaptan utilizando aplicaciones del mundo real. Algunos de los temas a cubrir incluyen preprocesamiento de texto, representación de texto, similitud, modelos recurrentes, así como incrustaciones (embeddings) de palabras\n",
    "\n",
    "\n",
    "## Requerimientos \n",
    "* [Python](http://www.python.org) versión >= 3.7;\n",
    "* [Numpy](http://www.numpy.org), Las extensiones numéricas básicas para el álgebra lineal y las matrices multidimensionales;\n",
    "* [Scipy](http://www.scipy.org), Bibliotecas adicionales para programación científica.;\n",
    "* [Matplotlib](http://matplotlib.sf.net), Excelentes bibliotecas de gráficos;\n",
    "* [IPython](http://ipython.org), con las bibliotecas adicionales necesarias para la interfaz del notebook.\n",
    "* [Pandas](http://pandas.pydata.org/), es una herramienta de análisis y manipulación de datos de código abierto rápida, potente, flexible y fácil de usar.\n",
    "* [Seaborn](stanford.edu/~mwaskom/software/seaborn/), Utilizado principalmente para el estilo de gráficos\n",
    "* [scikit-learn](http://scikit-learn.org), Librería para aprendizaje automático(Machine learning)\n",
    "* [nltk](https://www.nltk.org/), Una herramienta maravillosa para enseñar y trabajar en lingüística computacional usando Python.\n",
    "\n",
    "Una buena opción, fácil de instalar y compatible con Mac, Windows y Linux, y que tiene todos estos paquetes (y mucho más) es [Anaconda](https://www.continuum.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60eaba0-b897-42d3-bc4a-91e34bf1e461",
   "metadata": {},
   "source": [
    "# Procesamiento de Lenguaje Natural\n",
    "\n",
    "El procesamiento del lenguaje natural es el área que busca dotar a las computadoras con la capacidad de comprender el lenguaje natural del ser humano (escrito y hablado).\n",
    "\n",
    "![alt text](images/intro_nlp.png \"Title\")\n",
    "\n",
    "![alt text](images/concurso.png \"Title\")\n",
    "\n",
    "Dentro de los usos que tenemos actualmente de esta herramienta están las siguientes:\n",
    "\n",
    "+ Buscadores: Recuperación de información de corpus gigantescos.\n",
    "+ Generación de texto usando modelos de lenguaje: ¿Del conjunto de palabras de mi vocabulario cuál es la palabra más probable?\n",
    "\n",
    "![alt text](images/capital.png \"Title\")\n",
    "\n",
    "+ Generación de texto usando modelos de lenguaje: Chat GPT (Chat Generative Pre-Trained Transformer) por ejemplo\n",
    "\n",
    "![alt text](images/LLM-timeline.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952675c-da4d-4fb5-b930-a868b59bb8d9",
   "metadata": {},
   "source": [
    "# ¿Por qué el entendimiento del lenguaje es una tarea compleja?\n",
    "\n",
    "## Ambigüedad\n",
    "\n",
    "![alt text](images/ambig.png \"Title\")\n",
    "\n",
    "## Correferencia\n",
    "\n",
    "![alt text](images/corref.png \"Title\")\n",
    "\n",
    "## Sarcasmo/Ironía\n",
    "\n",
    "![alt text](images/sarcasmo.png \"Title\")\n",
    "\n",
    "## Otros\n",
    "\n",
    "+ Lenguaje no estándar (como los Tweets en X)\n",
    "+ Modismos (Camello, guayabo, entre otros)\n",
    "+ Neologismos (Textear, escanear, clickear, entre otros)\n",
    "+ Nombres de entidades (**De Música Ligera** fue grabado en ..., **Luisito Comunica** no ha dado declaraciones ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31817b8-7281-4642-b932-264949f8306c",
   "metadata": {},
   "source": [
    "# Problemas abordados en NLP\n",
    "\n",
    "+ Detección de Spam\n",
    "+ Análisis de polaridad\n",
    "+ Identificación de partes de la oración (POS)\n",
    "+ Identificación de entidades nombradas (NER)\n",
    "+ Recuperación de información\n",
    "+ Preguntas y respuestas\n",
    "+ Sistemas de diálogo\n",
    "+ Resúmenes automáticos\n",
    "\n",
    "![alt text](images/desafios.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01dff3-0ac0-48a1-9cfa-fc3ebc83c7db",
   "metadata": {},
   "source": [
    "# Práctica de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaee7e-a973-4cbd-8658-02b314b60916",
   "metadata": {},
   "source": [
    "### Tokenización\n",
    "\n",
    "En NLP el proceso de convertir nuestras secuencias de caracteres, palabras o párrafos en inputs para la computadora se llama **tokenización**. Se puede pensar al token como la unidad para procesamiento semántico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51247be-b337-4dde-8f0a-17b258b57095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tk = WhitespaceTokenizer()\n",
    "texto = \"¿Cuánto tiempo pasó desde que comí una manzana?\"\n",
    "texto_tokenizado = tk.tokenize(texto)\n",
    "print(texto_tokenizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d6c02-5ff3-4298-873b-7fbb800a7bb7",
   "metadata": {},
   "source": [
    "como vemos *manzana* y *cuánto* figuran con el signo de pregunta. Y si tuvieramos la palabra manzana mencionada otra vez saldría nuevamente como un token diferente. Lo mismo nos sucedería si aparece una coma o un punto ¿Cómo hacemos para evitarlo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f5c17-cd04-4ea5-a122-53826b82c0a9",
   "metadata": {},
   "source": [
    "Podemos utilizar `TreebankWordTokenizer` en lugar de `WhitespaceTokenizer`. También podemos preprocesar el texto quitando comas y signos de puntuación y separar por espacios, o bien utilizar opciones como `WordPunctTokenizer` que separa por palabras tomando como separadores todo lo que no sea un caracter alfabetico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d25b1-b1e7-4a9b-be77-720feaf63de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "texto = \"¿Cuánto tiempo pasó desde que comí una manzana?\"\n",
    "texto_tokenizado1 = WordPunctTokenizer().tokenize(texto)\n",
    "texto_tokenizado2 = TreebankWordTokenizer().tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9485d5-af40-4079-9fe2-a62d2953c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto_tokenizado1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ce0d2-9f4a-4a53-be7f-eac71e1b6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto_tokenizado2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15737e-57e4-4e3f-9b40-6ac87e0d7c6a",
   "metadata": {},
   "source": [
    "Como evidenciamos la opción de `TreebankWordTokenizer` es la más popular en inglés el signo de apertura de pregunta \"¿\" fue un problema para ella. Mientras que la opción de WordPunctTokenizer no tuvo ningún problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a986c5-26ca-4f65-8181-d722a2fefd1a",
   "metadata": {},
   "source": [
    "## One Hot Encoding de texto\n",
    "\n",
    "Vamos a revisar cómo obtener la representación de codificación one hot para nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db688a2-aa4f-4b40-b731-be772cdf3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75e89a-724f-4009-81f7-2ade11bd5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the vocabulary\n",
    "vocab = {}\n",
    "count = 0\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            count = count +1\n",
    "            vocab[word] = count\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f15e06-9271-41d3-b395-1299028d82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one hot representation for any string based on this vocabulary.\n",
    "#If the word exists in the vocabulary, its representation is returned.\n",
    "#If not, a list of zeroes is returned for that word.\n",
    "def get_onehot_vector(somestring):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab)\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]-1] = 1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94827da7-f6f5-4ee1-a9b3-0f3908730bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_docs[1])\n",
    "get_onehot_vector(processed_docs[1]) #one hot representation for a text from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da631d9d-b0f5-41c7-9c7b-45534e79fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_onehot_vector(\"man and dog are good\")\n",
    "#one hot representation for a random text, using the above vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed898a5-fe1d-434a-836d-20e30ac01777",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_onehot_vector(\"man and man are good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d371c8-b64a-4134-a3b8-d876c0bb972e",
   "metadata": {},
   "source": [
    "## One-hot encoding usando scikit -learn\n",
    "##### Codificamos nuestro corpus como una matriz numérica one-hot usando OneHotEncoder de scikit-learn.\n",
    "##### Mostraremos que:\n",
    "\n",
    "*   Codificación One-Hot: en la codificación One-Hot, a cada palabra w del vocabulario del corpus se le asigna un identificador entero único wid que está entre 1 y |V|, donde V es el conjunto del vocabulario del corpus. Cada palabra se representa entonces mediante un vector binario de dimensión V de 0 y 1.\n",
    "\n",
    "*   Codificación de etiquetas: en la codificación de etiquetas, cada palabra w en nuestro corpus se convierte en un valor numérico entre 0 y n-1 (donde n se refiere al número de palabras únicas en nuestro corpus).\n",
    "\n",
    "##### Se puede encontrar el enlace a la documentación oficial de ambos [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) y [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53c01c-67c2-4b3f-a21f-e3e57d76c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = 'dog bites man'\n",
    "S2 = 'man bites dog'\n",
    "S3 = 'dog eats meat'\n",
    "S4 = 'man eats food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4681a09-e1bd-4ba0-a218-d3c8d12c418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "data = [S1.split(), S2.split(), S3.split(), S4.split()]\n",
    "values = data[0]+data[1]+data[2]+data[3]\n",
    "print(\"The data: \",values)\n",
    "\n",
    "#Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Label Encoded:\",integer_encoded)\n",
    "\n",
    "#One-Hot Encoding\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoded = onehot_encoder.fit_transform(data).toarray()\n",
    "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53cfd2-0165-4d01-a602-056a37b0828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "list(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a89d6f-8a3b-4823-ae64-21d8cd9cb8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab70f1c6-42ac-4231-ad5f-fb1f0d51f21d",
   "metadata": {},
   "source": [
    "Esta representación es intuitiva y fácil de implementar, sin embargo, tiene algunas desventajas comos las siguientes:\n",
    "\n",
    "+ El tamaño del vector es proporcional al tamaño del vocabulario\n",
    "+ No proporciona una longitud fija entre documentos\n",
    "+ Las palabras son tomadas como unidades atómicas y no hay una noción de similitud (disimilitud)\n",
    "+ No maneja un esquema fuera del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348dcebc-eed8-4c5a-8138-71308c6a54a7",
   "metadata": {},
   "source": [
    "## Bag of Words (Bolsa de palabras)\n",
    "\n",
    "Ahora, veremos cómo utilizar la representación de bolsa de palabras para los mismos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98af35-ee43-4327-a43a-9e57b3147ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"] #Same as the earlier notebook\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b88b0-5cab-4986-83f5-78500a9493c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the documents list\n",
    "print(\"Our corpus: \", processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7975e6-9e66-44a7-aff9-a0227ad40637",
   "metadata": {},
   "source": [
    "Ahora, realicemos la tarea principal de encontrar la representación de la bolsa de palabras. Usaremos CountVectorizer de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17618b1-4471-414d-a927-bb67f6d3f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76321a41-9515-47b4-9274-bb4a49e135a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7d0e7-ec46-4c52-b50d-261ddeb649cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65595017-e926-4534-90db-402532219a9d",
   "metadata": {},
   "source": [
    "En el código anterior, representamos el texto teniendo en cuenta la frecuencia de las palabras. Sin embargo, a veces no nos importa mucho la frecuencia, sino que solo queremos saber si una palabra apareció en un texto o no. Es decir, cada documento se representa como un vector de 0 y 1. Para ello, utilizaremos la opción binary=True en CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ea7c3-d4a3-4e09-bf7d-d2c5b54ed879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW with binary vectors\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "count_vect.fit(processed_docs)\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd87877-0a7c-4424-b5aa-9b5143858ad3",
   "metadata": {},
   "source": [
    "Algunas ventajas de esta estrategia son las siguientes:\n",
    "\n",
    "+ Intuitiva y fácil de implementar\n",
    "+ Captura la similitud semántica de los documentos\n",
    "+ Codificación de longitud fija para cualquier oración arbitraria\n",
    "\n",
    "Sin embargo, tambien tiene algunas desventajas:\n",
    "\n",
    "+ El tamaño del vector aumenta con el tamaño del vocabulario\n",
    "+ No captura la similitud semántica de palabras que significan lo mismo\n",
    "+ No tiene forma de manejar palabras fuera del vocabulario\n",
    "+ El orden de las palabras se pierde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72372242-b317-4ccf-b0c5-028db53e9276",
   "metadata": {},
   "source": [
    "## Bolsa de N-Gramas\n",
    "\n",
    "Una codificación tipo One-Hot, BoW y TF-IDF tratan las palabras como unidades independientes. No existe la noción de frases ni ordenamiento de palabras. El enfoque de la Bolsa de N-Gramas (BoN) intenta remediar esto. Lo hace dividiendo el texto en fragmentos de n palabras o tokens contiguos. Esto puede ayudarnos a capturar algo de contexto, algo que los enfoques anteriores no podían hacer. Veamos cómo funciona utilizando el mismo corpus que usamos en los ejemplos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fabd3-adda-4c0e-83a0-8c1fd1789910",
   "metadata": {},
   "source": [
    "CountVectorizer, que usamos para BoW, también se puede usar para obtener una representación de bolsa de N-gramas, usando su argumento ngram_range. El fragmento de código a continuación muestra cómo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff6745-50ad-482f-995e-3fc1e09668bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Ngram vectorization example with count vectorizer and uni, bi, trigrams\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a7fbc-5a84-48be-a8d2-805e20ca6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the BOW rep for 1 term\n",
    "term_rep = count_vect.transform([\"dog\"])\n",
    "print(\"BoW representation for 'dog': \", term_rep.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60b94e-bf9f-4568-8af3-e0dd358cb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the BOW rep for 1 term\n",
    "term_rep = count_vect.transform([\"bites\"])\n",
    "print(\"BoW representation for 'bites': \", term_rep.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420baba-3572-44a3-aa96-4758593c3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the BOW rep for 1 term\n",
    "term_rep = count_vect.transform([\"dog bites\"])\n",
    "print(\"BoW representation for 'dog bites': \", term_rep.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa8e19-271c-440a-a078-d6248253a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b0e58-d0ec-4d16-9956-7dcebfda7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8701e0b0-a556-4d89-9d58-a59ddf69e577",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el número de características (y, por lo tanto, el tamaño del vector de características) aumentó mucho para los mismos datos, en comparación con las otras representaciones basadas en una sola palabra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e17eb1-f9c3-4d07-a22e-0619ec23faba",
   "metadata": {},
   "source": [
    "Algunos pro que tiene esta estrategia son:\n",
    "\n",
    "+ Captura alguna información del contexto y orden de las palabras\n",
    "+ El espacio captura similitud semántica\n",
    "\n",
    "Y algunos contra que tiene esta estrategia son:\n",
    "\n",
    "+ A medida que aumenta el número de palabras contiguas (n) la dimensionalidad aumenta\n",
    "+ Aún no hay una estrategia para abordar el problema de palabras fuera del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7fe3c-52d6-4e3a-960d-ff7e614788a0",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Término de frecuencia - frecuencia de documento inversa, cuantifica la importancia de una palabra en relación con otras palabras en el documento y en el corpus.\n",
    "\n",
    "El TF cuantifica la frecuencia de un término o una palabra en un documento.\n",
    "\n",
    "$TF(t, d) = \\frac{\\text{# de ocurrencias del término } t \\text{ en el documento }d}{\\text{# de términos en el documento } d}$\n",
    "\n",
    "El IDF cuantifica la importancia del término o palabra en todo el corpus.\n",
    "\n",
    "$IDF(t) = \\ln\\left(\\frac{\\text{Número total de documentos en el corpus}}{\\text{Número de documentos con el término } t \\text{en ellos}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d6228-630a-4b80-8f3d-013c9618f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253d8a9-26a5-497e-abe4-f35f5bb64257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDF for all words in the vocabulary\n",
    "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd516054-0f63-4bec-b33f-4c5a6fa6cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All words in the vocabulary.\n",
    "print(\"All words in the vocabulary\",tfidf.vocabulary_)\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dec7e2-1e09-43b5-9d00-5a3d98b23950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF representation for all documents in our corpus\n",
    "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray())\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e907d8d-b46a-426b-8e0b-434605f2a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
